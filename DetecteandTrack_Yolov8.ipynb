{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a6aa1a7b6eb4e8c904f49de018c6563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ab929030cd845e1ae82ba7d38fc7a63",
              "IPY_MODEL_4ccc869c152a4d2a98e1164647720635",
              "IPY_MODEL_d336bbd011ee4c5bba23900178c94b98"
            ],
            "layout": "IPY_MODEL_726777bbfbd2481dad634541172a62f4"
          }
        },
        "7ab929030cd845e1ae82ba7d38fc7a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1229074f174b4c8d2d24013cb51435",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2207fb308748e3a11b9464ed1ab437",
            "value": "100%"
          }
        },
        "4ccc869c152a4d2a98e1164647720635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf1bd0c694e40ef827bfbf358ffefa9",
            "max": 136867539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c693991c15f4c43a503421e5f18497e",
            "value": 136867539
          }
        },
        "d336bbd011ee4c5bba23900178c94b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06260270204b42d7abde0031a6472ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_080f310aa8324f59a57f691b605b1d4a",
            "value": " 131M/131M [00:06&lt;00:00, 20.4MB/s]"
          }
        },
        "726777bbfbd2481dad634541172a62f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1229074f174b4c8d2d24013cb51435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2207fb308748e3a11b9464ed1ab437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf1bd0c694e40ef827bfbf358ffefa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c693991c15f4c43a503421e5f18497e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06260270204b42d7abde0031a6472ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "080f310aa8324f59a57f691b605b1d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "280f97db9c6e43f6baf3fab659d2cc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c4c05be880440a48252a93ba731e9af",
              "IPY_MODEL_7805285f4c34481981ee60676675d140",
              "IPY_MODEL_88e8840fd2984f8eae6b8f8560d9b35a"
            ],
            "layout": "IPY_MODEL_22baab2235b34b8b90b8fab1f0dc3912"
          }
        },
        "0c4c05be880440a48252a93ba731e9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99a7918f26834f9094b9490fc777868b",
            "placeholder": "​",
            "style": "IPY_MODEL_5110f10f5b454adba5a04978cc81732d",
            "value": "100%"
          }
        },
        "7805285f4c34481981ee60676675d140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e1b0ac00814580aab27178f0031e08",
            "max": 538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_440162b3a1524e94abb30de882aad1f6",
            "value": 538
          }
        },
        "88e8840fd2984f8eae6b8f8560d9b35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cb65fe170d487f9906e915cf5e2c35",
            "placeholder": "​",
            "style": "IPY_MODEL_b7a07c9d6e3448afa5cfed5fbebd7c55",
            "value": " 538/538 [01:46&lt;00:00,  7.11it/s]"
          }
        },
        "22baab2235b34b8b90b8fab1f0dc3912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a7918f26834f9094b9490fc777868b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5110f10f5b454adba5a04978cc81732d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e1b0ac00814580aab27178f0031e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440162b3a1524e94abb30de882aad1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98cb65fe170d487f9906e915cf5e2c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a07c9d6e3448afa5cfed5fbebd7c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2D Object Detection"
      ],
      "metadata": {
        "id": "Cb1_bzqtMrG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "!cd ByteTrack && pip3 install -q -r requirements.txt\n",
        "!cd ByteTrack && python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "!pip install ultralytics\n",
        "!pip install supervision==0.1.0\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "\n",
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False\n",
        "\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1CXdTL-MpPn",
        "outputId": "b219f195-2057-42d1-ccdf-7cb2886b738f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download video"
      ],
      "metadata": {
        "id": "J_Zyej4SSZNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctvdpAiRSb1_",
        "outputId": "be1f5221-eca2-4e4d-eb82-dc7bd74ea8d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-06 18:41:38--  https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "Resolving docs.google.com (docs.google.com)... 172.253.117.138, 172.253.117.101, 172.253.117.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.253.117.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-ag-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tb3dn33olm77ktq22h80g19slbn2i2tc/1678128075000/04309230031174164349/*/1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-?e=download&uuid=a418645f-6d6d-4226-b1d5-2dbd1bfb0f96 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-06 18:41:39--  https://doc-0s-ag-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tb3dn33olm77ktq22h80g19slbn2i2tc/1678128075000/04309230031174164349/*/1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-?e=download&uuid=a418645f-6d6d-4226-b1d5-2dbd1bfb0f96\n",
            "Resolving doc-0s-ag-docs.googleusercontent.com (doc-0s-ag-docs.googleusercontent.com)... 74.125.135.132, 2607:f8b0:400e:c01::84\n",
            "Connecting to doc-0s-ag-docs.googleusercontent.com (doc-0s-ag-docs.googleusercontent.com)|74.125.135.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35345757 (34M) [video/mp4]\n",
            "Saving to: ‘vehicle-counting.mp4’\n",
            "\n",
            "vehicle-counting.mp 100%[===================>]  33.71M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-06 18:41:40 (225 MB/s) - ‘vehicle-counting.mp4’ saved [35345757/35345757]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"vehicle-counting.mp4\""
      ],
      "metadata": {
        "id": "gtxQLn33TBWo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Roboflow Supervision"
      ],
      "metadata": {
        "id": "_kSHFj8uQ9qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60yX_PFQ9A2",
        "outputId": "4ab62341-9629-448e-cb73-26cfa810ada2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking utils\n",
        "\n",
        "Unfortunately, we have to manually match the bounding boxes coming from our model with those created by the tracker."
      ],
      "metadata": {
        "id": "mPdB-v_hWxBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections, \n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "    \n",
        "    tracker_ids = [None] * len(detections)\n",
        "    \n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "SE0G6LvFAXlk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained YOLOv8 model"
      ],
      "metadata": {
        "id": "c_417m4g9XVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "MODEL = \"yolov8x.pt\""
      ],
      "metadata": {
        "id": "m3FMq5FcUsRc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n"
      ],
      "metadata": {
        "id": "mXUyy32VOz7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0a6aa1a7b6eb4e8c904f49de018c6563",
            "7ab929030cd845e1ae82ba7d38fc7a63",
            "4ccc869c152a4d2a98e1164647720635",
            "d336bbd011ee4c5bba23900178c94b98",
            "726777bbfbd2481dad634541172a62f4",
            "6d1229074f174b4c8d2d24013cb51435",
            "4b2207fb308748e3a11b9464ed1ab437",
            "5cf1bd0c694e40ef827bfbf358ffefa9",
            "3c693991c15f4c43a503421e5f18497e",
            "06260270204b42d7abde0031a6472ecd",
            "080f310aa8324f59a57f691b605b1d4a"
          ]
        },
        "id": "KFCV_2TR9eo_",
        "outputId": "1c136b73-7c2c-41ff-8ad7-3109983e97f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to yolov8x.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/131M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a6aa1a7b6eb4e8c904f49de018c6563"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and annotate single frame"
      ],
      "metadata": {
        "id": "6to6MgPmTnCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "yKuDnOIxsN6l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "# annotate and display frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "hZQsgCa0cFvH",
        "outputId": "210b8429-72a0-4621-a195-ad9db776be0f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.3ms\n",
            "Speed: 0.7ms preprocess, 64.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cb6e5674c651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# annotate and display frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_annotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_frame_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and annotate whole video "
      ],
      "metadata": {
        "id": "3ZbGmYfiT0EV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "LINE_START = Point(50, 1500)\n",
        "LINE_END = Point(3840-50, 1500)\n",
        "\n",
        "TARGET_VIDEO_PATH = f\"vehicle-counting-result.mp4\""
      ],
      "metadata": {
        "id": "MjP8Pn10XuJm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btq7JavXknU",
        "outputId": "e5c2d2fb-d0fc-408f-aaa0-6287466f1c25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VideoInfo(width=3840, height=2160, fps=25, total_frames=538)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "280f97db9c6e43f6baf3fab659d2cc5a",
            "0c4c05be880440a48252a93ba731e9af",
            "7805285f4c34481981ee60676675d140",
            "88e8840fd2984f8eae6b8f8560d9b35a",
            "22baab2235b34b8b90b8fab1f0dc3912",
            "99a7918f26834f9094b9490fc777868b",
            "5110f10f5b454adba5a04978cc81732d",
            "c2e1b0ac00814580aab27178f0031e08",
            "440162b3a1524e94abb30de882aad1f6",
            "98cb65fe170d487f9906e915cf5e2c35",
            "b7a07c9d6e3448afa5cfed5fbebd7c55"
          ]
        },
        "id": "Q9ppb7bFvWfc",
        "outputId": "455187ab-ea70-4e90-cc2c-bc1468cab0d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "280f97db9c6e43f6baf3fab659d2cc5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 67.2ms\n",
            "Speed: 0.6ms preprocess, 67.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 66.6ms\n",
            "Speed: 0.6ms preprocess, 66.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 67.7ms\n",
            "Speed: 0.6ms preprocess, 67.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 77.8ms\n",
            "Speed: 2.0ms preprocess, 77.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 67.5ms\n",
            "Speed: 0.6ms preprocess, 67.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 64.2ms\n",
            "Speed: 0.7ms preprocess, 64.2ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 70.6ms\n",
            "Speed: 0.6ms preprocess, 70.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 6.9ms preprocess, 64.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 70.0ms\n",
            "Speed: 0.7ms preprocess, 70.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 67.1ms\n",
            "Speed: 0.6ms preprocess, 67.1ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.6ms\n",
            "Speed: 0.6ms preprocess, 64.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 73.7ms\n",
            "Speed: 0.6ms preprocess, 73.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 68.9ms\n",
            "Speed: 0.6ms preprocess, 68.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 72.4ms\n",
            "Speed: 0.6ms preprocess, 72.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 78.5ms\n",
            "Speed: 0.6ms preprocess, 78.5ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 70.4ms\n",
            "Speed: 0.6ms preprocess, 70.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 77.6ms\n",
            "Speed: 5.6ms preprocess, 77.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 72.6ms\n",
            "Speed: 0.6ms preprocess, 72.6ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 78.5ms\n",
            "Speed: 10.7ms preprocess, 78.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 124.8ms\n",
            "Speed: 0.6ms preprocess, 124.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 67.0ms\n",
            "Speed: 1.6ms preprocess, 67.0ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 77.7ms\n",
            "Speed: 0.6ms preprocess, 77.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 74.6ms\n",
            "Speed: 0.6ms preprocess, 74.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 64.8ms\n",
            "Speed: 0.6ms preprocess, 64.8ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 74.7ms\n",
            "Speed: 0.6ms preprocess, 74.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 77.1ms\n",
            "Speed: 0.6ms preprocess, 77.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 83.3ms\n",
            "Speed: 0.7ms preprocess, 83.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 65.3ms\n",
            "Speed: 0.7ms preprocess, 65.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 1 traffic light, 64.0ms\n",
            "Speed: 0.7ms preprocess, 64.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 91.8ms\n",
            "Speed: 0.6ms preprocess, 91.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 112.4ms\n",
            "Speed: 3.1ms preprocess, 112.4ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 66.2ms\n",
            "Speed: 0.6ms preprocess, 66.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 123.7ms\n",
            "Speed: 0.6ms preprocess, 123.7ms inference, 22.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 143.4ms\n",
            "Speed: 1.1ms preprocess, 143.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 101.8ms\n",
            "Speed: 0.6ms preprocess, 101.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 80.9ms\n",
            "Speed: 2.8ms preprocess, 80.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 71.4ms\n",
            "Speed: 0.6ms preprocess, 71.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.5ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.7ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 65.4ms\n",
            "Speed: 0.7ms preprocess, 65.4ms inference, 13.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.9ms preprocess, 64.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.7ms preprocess, 64.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 65.2ms\n",
            "Speed: 0.8ms preprocess, 65.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 60.0ms\n",
            "Speed: 0.6ms preprocess, 60.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 52.0ms\n",
            "Speed: 0.7ms preprocess, 52.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 58.1ms\n",
            "Speed: 0.6ms preprocess, 58.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 53.4ms\n",
            "Speed: 0.7ms preprocess, 53.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 51.9ms\n",
            "Speed: 0.6ms preprocess, 51.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 55.0ms\n",
            "Speed: 0.6ms preprocess, 55.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 68.0ms\n",
            "Speed: 0.6ms preprocess, 68.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 68.6ms\n",
            "Speed: 0.6ms preprocess, 68.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.1ms\n",
            "Speed: 1.3ms preprocess, 64.1ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.9ms\n",
            "Speed: 0.9ms preprocess, 64.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 65.4ms\n",
            "Speed: 0.6ms preprocess, 65.4ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 67.9ms\n",
            "Speed: 0.6ms preprocess, 67.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 66.4ms\n",
            "Speed: 0.6ms preprocess, 66.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 67.5ms\n",
            "Speed: 0.6ms preprocess, 67.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.5ms\n",
            "Speed: 0.6ms preprocess, 64.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 61.9ms\n",
            "Speed: 0.6ms preprocess, 61.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 61.5ms\n",
            "Speed: 0.6ms preprocess, 61.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 3 trucks, 61.5ms\n",
            "Speed: 0.6ms preprocess, 61.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 61.6ms\n",
            "Speed: 0.6ms preprocess, 61.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 58.2ms\n",
            "Speed: 0.6ms preprocess, 58.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 53.9ms\n",
            "Speed: 0.6ms preprocess, 53.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 53.9ms\n",
            "Speed: 0.6ms preprocess, 53.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 53.9ms\n",
            "Speed: 0.7ms preprocess, 53.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.0ms\n",
            "Speed: 0.7ms preprocess, 54.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 53.9ms\n",
            "Speed: 0.7ms preprocess, 53.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 54.3ms\n",
            "Speed: 0.6ms preprocess, 54.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 1 bench, 52.9ms\n",
            "Speed: 0.6ms preprocess, 52.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 1 bench, 53.2ms\n",
            "Speed: 0.6ms preprocess, 53.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 refrigerator, 51.8ms\n",
            "Speed: 0.6ms preprocess, 51.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 49.2ms\n",
            "Speed: 0.6ms preprocess, 49.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 49.4ms\n",
            "Speed: 0.6ms preprocess, 49.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 48.8ms\n",
            "Speed: 1.4ms preprocess, 48.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 refrigerator, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.6ms\n",
            "Speed: 0.6ms preprocess, 49.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.3ms\n",
            "Speed: 0.6ms preprocess, 49.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.3ms\n",
            "Speed: 0.6ms preprocess, 49.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.7ms preprocess, 48.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.7ms\n",
            "Speed: 0.6ms preprocess, 48.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.9ms\n",
            "Speed: 0.6ms preprocess, 46.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.7ms\n",
            "Speed: 0.7ms preprocess, 46.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.7ms\n",
            "Speed: 0.7ms preprocess, 46.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.8ms\n",
            "Speed: 0.8ms preprocess, 46.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.8ms\n",
            "Speed: 0.6ms preprocess, 46.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.7ms\n",
            "Speed: 0.6ms preprocess, 46.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.7ms\n",
            "Speed: 0.6ms preprocess, 46.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.9ms\n",
            "Speed: 0.6ms preprocess, 46.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.6ms\n",
            "Speed: 0.6ms preprocess, 47.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.9ms\n",
            "Speed: 0.6ms preprocess, 46.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.6ms\n",
            "Speed: 0.6ms preprocess, 51.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.5ms\n",
            "Speed: 0.7ms preprocess, 50.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.5ms\n",
            "Speed: 0.6ms preprocess, 46.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.3ms\n",
            "Speed: 0.6ms preprocess, 45.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.8ms\n",
            "Speed: 0.7ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.5ms\n",
            "Speed: 0.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.4ms\n",
            "Speed: 0.7ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.8ms\n",
            "Speed: 0.6ms preprocess, 41.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.5ms\n",
            "Speed: 0.7ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 0.8ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.4ms\n",
            "Speed: 0.7ms preprocess, 40.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.6ms\n",
            "Speed: 0.7ms preprocess, 41.6ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 0.8ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 0.7ms preprocess, 40.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.1ms\n",
            "Speed: 0.6ms preprocess, 41.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.8ms\n",
            "Speed: 0.6ms preprocess, 46.8ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.4ms\n",
            "Speed: 3.1ms preprocess, 49.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.2ms\n",
            "Speed: 0.6ms preprocess, 55.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.0ms\n",
            "Speed: 0.6ms preprocess, 53.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 56.0ms\n",
            "Speed: 0.6ms preprocess, 56.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 61.2ms\n",
            "Speed: 0.6ms preprocess, 61.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.7ms\n",
            "Speed: 0.6ms preprocess, 62.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 60.1ms\n",
            "Speed: 0.6ms preprocess, 60.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 61.3ms\n",
            "Speed: 0.5ms preprocess, 61.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 74.7ms\n",
            "Speed: 0.5ms preprocess, 74.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 87.1ms\n",
            "Speed: 0.6ms preprocess, 87.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 69.8ms\n",
            "Speed: 0.6ms preprocess, 69.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 74.6ms\n",
            "Speed: 0.6ms preprocess, 74.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.3ms\n",
            "Speed: 0.6ms preprocess, 68.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 67.1ms\n",
            "Speed: 0.6ms preprocess, 67.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 65.9ms\n",
            "Speed: 7.3ms preprocess, 65.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 72.0ms\n",
            "Speed: 0.6ms preprocess, 72.0ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 67.0ms\n",
            "Speed: 0.6ms preprocess, 67.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 65.1ms\n",
            "Speed: 0.6ms preprocess, 65.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 117.7ms\n",
            "Speed: 0.6ms preprocess, 117.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.6ms\n",
            "Speed: 0.6ms preprocess, 64.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 72.8ms\n",
            "Speed: 0.6ms preprocess, 72.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 66.1ms\n",
            "Speed: 0.6ms preprocess, 66.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 66.2ms\n",
            "Speed: 0.6ms preprocess, 66.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.3ms\n",
            "Speed: 0.6ms preprocess, 68.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 84.4ms\n",
            "Speed: 0.6ms preprocess, 84.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 65.7ms\n",
            "Speed: 0.6ms preprocess, 65.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.5ms\n",
            "Speed: 0.6ms preprocess, 68.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.0ms\n",
            "Speed: 0.7ms preprocess, 68.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 70.6ms\n",
            "Speed: 0.6ms preprocess, 70.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 71.1ms\n",
            "Speed: 0.6ms preprocess, 71.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 71.7ms\n",
            "Speed: 0.7ms preprocess, 71.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 5.7ms preprocess, 64.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 65.3ms\n",
            "Speed: 0.6ms preprocess, 65.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.9ms preprocess, 64.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.6ms\n",
            "Speed: 0.6ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.6ms\n",
            "Speed: 2.7ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.5ms\n",
            "Speed: 0.6ms preprocess, 49.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.7ms\n",
            "Speed: 0.7ms preprocess, 49.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.5ms\n",
            "Speed: 0.6ms preprocess, 49.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.7ms\n",
            "Speed: 3.4ms preprocess, 49.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.8ms\n",
            "Speed: 0.6ms preprocess, 49.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.8ms\n",
            "Speed: 0.6ms preprocess, 49.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.4ms\n",
            "Speed: 0.6ms preprocess, 49.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.8ms\n",
            "Speed: 0.6ms preprocess, 57.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.5ms\n",
            "Speed: 0.6ms preprocess, 62.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 61.2ms\n",
            "Speed: 0.6ms preprocess, 61.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 66.2ms\n",
            "Speed: 0.6ms preprocess, 66.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 66.5ms\n",
            "Speed: 0.6ms preprocess, 66.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 65.3ms\n",
            "Speed: 0.6ms preprocess, 65.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 66.8ms\n",
            "Speed: 0.6ms preprocess, 66.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.3ms\n",
            "Speed: 2.6ms preprocess, 64.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.5ms\n",
            "Speed: 0.6ms preprocess, 64.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.6ms\n",
            "Speed: 0.6ms preprocess, 62.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 60.2ms\n",
            "Speed: 0.6ms preprocess, 60.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 58.1ms\n",
            "Speed: 0.6ms preprocess, 58.1ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.0ms\n",
            "Speed: 0.6ms preprocess, 57.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.3ms\n",
            "Speed: 0.6ms preprocess, 57.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 61.0ms\n",
            "Speed: 0.6ms preprocess, 61.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 56.7ms\n",
            "Speed: 0.9ms preprocess, 56.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.6ms\n",
            "Speed: 0.6ms preprocess, 55.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.7ms preprocess, 48.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.8ms\n",
            "Speed: 0.6ms preprocess, 48.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.8ms\n",
            "Speed: 0.6ms preprocess, 48.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.3ms\n",
            "Speed: 0.8ms preprocess, 49.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.3ms\n",
            "Speed: 0.6ms preprocess, 49.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.8ms\n",
            "Speed: 0.6ms preprocess, 48.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.7ms\n",
            "Speed: 0.6ms preprocess, 51.7ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.8ms\n",
            "Speed: 0.6ms preprocess, 48.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.0ms\n",
            "Speed: 0.7ms preprocess, 49.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.7ms\n",
            "Speed: 0.7ms preprocess, 51.7ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.2ms\n",
            "Speed: 0.6ms preprocess, 54.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.1ms\n",
            "Speed: 0.7ms preprocess, 54.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.1ms\n",
            "Speed: 0.6ms preprocess, 53.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.0ms\n",
            "Speed: 0.6ms preprocess, 48.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.0ms\n",
            "Speed: 0.6ms preprocess, 48.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.0ms\n",
            "Speed: 0.7ms preprocess, 48.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.0ms\n",
            "Speed: 0.6ms preprocess, 48.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.1ms\n",
            "Speed: 0.6ms preprocess, 48.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 48.3ms\n",
            "Speed: 0.8ms preprocess, 48.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.5ms\n",
            "Speed: 0.6ms preprocess, 50.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.3ms\n",
            "Speed: 0.6ms preprocess, 50.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.0ms\n",
            "Speed: 1.2ms preprocess, 52.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 53.3ms\n",
            "Speed: 0.6ms preprocess, 53.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 74.7ms\n",
            "Speed: 0.6ms preprocess, 74.7ms inference, 10.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 61.3ms\n",
            "Speed: 0.6ms preprocess, 61.3ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.0ms\n",
            "Speed: 0.6ms preprocess, 68.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 66.5ms\n",
            "Speed: 0.6ms preprocess, 66.5ms inference, 9.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 70.0ms\n",
            "Speed: 0.6ms preprocess, 70.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.9ms\n",
            "Speed: 0.6ms preprocess, 68.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 70.8ms\n",
            "Speed: 0.6ms preprocess, 70.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 55.2ms\n",
            "Speed: 0.6ms preprocess, 55.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.4ms\n",
            "Speed: 0.6ms preprocess, 51.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.1ms\n",
            "Speed: 0.6ms preprocess, 46.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 60.3ms\n",
            "Speed: 0.6ms preprocess, 60.3ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.4ms\n",
            "Speed: 0.7ms preprocess, 51.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 49.5ms\n",
            "Speed: 0.6ms preprocess, 49.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.3ms\n",
            "Speed: 1.4ms preprocess, 46.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.8ms\n",
            "Speed: 0.8ms preprocess, 46.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 1 traffic light, 58.0ms\n",
            "Speed: 0.6ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 3 trucks, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 68.6ms\n",
            "Speed: 0.5ms preprocess, 68.6ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 68.2ms\n",
            "Speed: 0.7ms preprocess, 68.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 64.2ms\n",
            "Speed: 0.5ms preprocess, 64.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 64.1ms\n",
            "Speed: 1.1ms preprocess, 64.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 67.2ms\n",
            "Speed: 0.6ms preprocess, 67.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 64.1ms\n",
            "Speed: 0.9ms preprocess, 64.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 65.5ms\n",
            "Speed: 0.7ms preprocess, 65.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 63.8ms\n",
            "Speed: 0.6ms preprocess, 63.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.6ms\n",
            "Speed: 0.6ms preprocess, 55.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.8ms\n",
            "Speed: 0.6ms preprocess, 55.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.7ms\n",
            "Speed: 0.6ms preprocess, 55.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 55.2ms\n",
            "Speed: 0.6ms preprocess, 55.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.8ms\n",
            "Speed: 2.4ms preprocess, 54.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.6ms\n",
            "Speed: 0.7ms preprocess, 52.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 219.2ms\n",
            "Speed: 0.6ms preprocess, 219.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.6ms\n",
            "Speed: 0.6ms preprocess, 52.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.5ms\n",
            "Speed: 0.6ms preprocess, 52.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.5ms\n",
            "Speed: 0.7ms preprocess, 52.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 50.0ms\n",
            "Speed: 0.6ms preprocess, 50.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 50.3ms\n",
            "Speed: 0.6ms preprocess, 50.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.8ms\n",
            "Speed: 0.6ms preprocess, 43.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.9ms\n",
            "Speed: 1.8ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.0ms\n",
            "Speed: 0.6ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.6ms preprocess, 42.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.0ms\n",
            "Speed: 0.6ms preprocess, 42.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.6ms\n",
            "Speed: 0.7ms preprocess, 40.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 0.7ms preprocess, 40.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.6ms preprocess, 42.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 46.1ms\n",
            "Speed: 0.6ms preprocess, 46.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 47.4ms\n",
            "Speed: 0.6ms preprocess, 47.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 47.9ms\n",
            "Speed: 0.6ms preprocess, 47.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.1ms\n",
            "Speed: 3.6ms preprocess, 48.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 49.6ms\n",
            "Speed: 0.6ms preprocess, 49.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 49.6ms\n",
            "Speed: 0.6ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 51.2ms\n",
            "Speed: 0.7ms preprocess, 51.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 51.8ms\n",
            "Speed: 0.6ms preprocess, 51.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.1ms\n",
            "Speed: 0.6ms preprocess, 46.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.8ms preprocess, 46.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.8ms\n",
            "Speed: 1.3ms preprocess, 52.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.1ms\n",
            "Speed: 0.6ms preprocess, 46.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.5ms\n",
            "Speed: 0.6ms preprocess, 46.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.1ms\n",
            "Speed: 0.6ms preprocess, 46.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.2ms\n",
            "Speed: 0.6ms preprocess, 46.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.8ms\n",
            "Speed: 0.6ms preprocess, 46.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.8ms\n",
            "Speed: 0.6ms preprocess, 48.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.8ms\n",
            "Speed: 1.0ms preprocess, 48.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.5ms\n",
            "Speed: 0.6ms preprocess, 54.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 54.6ms\n",
            "Speed: 0.6ms preprocess, 54.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 66.6ms\n",
            "Speed: 0.8ms preprocess, 66.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 61.7ms\n",
            "Speed: 0.7ms preprocess, 61.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 61.3ms\n",
            "Speed: 0.6ms preprocess, 61.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 65.2ms\n",
            "Speed: 0.6ms preprocess, 65.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 61.8ms\n",
            "Speed: 0.6ms preprocess, 61.8ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.5ms\n",
            "Speed: 0.6ms preprocess, 64.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 66.6ms\n",
            "Speed: 3.2ms preprocess, 66.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 64.8ms\n",
            "Speed: 0.6ms preprocess, 64.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 64.0ms\n",
            "Speed: 0.8ms preprocess, 64.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 65.7ms\n",
            "Speed: 0.6ms preprocess, 65.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 65.1ms\n",
            "Speed: 0.6ms preprocess, 65.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 63.2ms\n",
            "Speed: 0.6ms preprocess, 63.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 61.5ms\n",
            "Speed: 0.6ms preprocess, 61.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 58.9ms\n",
            "Speed: 5.8ms preprocess, 58.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 59.1ms\n",
            "Speed: 0.6ms preprocess, 59.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 58.9ms\n",
            "Speed: 0.6ms preprocess, 58.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 56.8ms\n",
            "Speed: 0.6ms preprocess, 56.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.0ms\n",
            "Speed: 0.6ms preprocess, 53.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.1ms\n",
            "Speed: 0.6ms preprocess, 53.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.3ms\n",
            "Speed: 0.6ms preprocess, 53.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.4ms\n",
            "Speed: 0.6ms preprocess, 53.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 50.4ms\n",
            "Speed: 0.6ms preprocess, 50.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.2ms\n",
            "Speed: 0.6ms preprocess, 51.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 50.4ms\n",
            "Speed: 0.6ms preprocess, 50.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 56.2ms\n",
            "Speed: 0.6ms preprocess, 56.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.0ms\n",
            "Speed: 0.8ms preprocess, 42.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.1ms\n",
            "Speed: 0.6ms preprocess, 42.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.0ms\n",
            "Speed: 0.6ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.0ms\n",
            "Speed: 0.6ms preprocess, 42.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.1ms\n",
            "Speed: 0.7ms preprocess, 42.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.9ms\n",
            "Speed: 2.0ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.0ms\n",
            "Speed: 0.6ms preprocess, 42.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.4ms\n",
            "Speed: 0.7ms preprocess, 42.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 48.3ms\n",
            "Speed: 0.6ms preprocess, 48.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.7ms\n",
            "Speed: 0.6ms preprocess, 46.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.9ms\n",
            "Speed: 0.6ms preprocess, 40.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.0ms\n",
            "Speed: 0.6ms preprocess, 41.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.0ms\n",
            "Speed: 0.7ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.5ms\n",
            "Speed: 0.7ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.6ms\n",
            "Speed: 0.7ms preprocess, 40.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.8ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.7ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.3ms\n",
            "Speed: 0.7ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.7ms\n",
            "Speed: 0.6ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.6ms\n",
            "Speed: 0.6ms preprocess, 41.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 0.6ms preprocess, 41.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.4ms\n",
            "Speed: 0.6ms preprocess, 42.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.1ms\n",
            "Speed: 0.6ms preprocess, 45.1ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.8ms preprocess, 46.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.8ms\n",
            "Speed: 0.6ms preprocess, 46.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.4ms\n",
            "Speed: 0.6ms preprocess, 48.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.2ms\n",
            "Speed: 0.7ms preprocess, 48.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.7ms\n",
            "Speed: 0.6ms preprocess, 44.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.6ms\n",
            "Speed: 0.6ms preprocess, 48.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.1ms\n",
            "Speed: 0.6ms preprocess, 43.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.1ms\n",
            "Speed: 2.0ms preprocess, 47.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.4ms\n",
            "Speed: 0.5ms preprocess, 44.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 73.5ms\n",
            "Speed: 0.6ms preprocess, 73.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.0ms\n",
            "Speed: 1.9ms preprocess, 64.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 67.2ms\n",
            "Speed: 0.6ms preprocess, 67.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 72.8ms\n",
            "Speed: 0.9ms preprocess, 72.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 1 traffic light, 64.0ms\n",
            "Speed: 0.7ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 65.5ms\n",
            "Speed: 0.7ms preprocess, 65.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 61.3ms\n",
            "Speed: 0.6ms preprocess, 61.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 58.5ms\n",
            "Speed: 0.6ms preprocess, 58.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.2ms\n",
            "Speed: 0.6ms preprocess, 55.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 62.1ms\n",
            "Speed: 0.5ms preprocess, 62.1ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.7ms\n",
            "Speed: 0.6ms preprocess, 54.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.7ms\n",
            "Speed: 0.7ms preprocess, 54.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 63.5ms\n",
            "Speed: 0.7ms preprocess, 63.5ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.7ms\n",
            "Speed: 0.6ms preprocess, 54.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.7ms\n",
            "Speed: 0.6ms preprocess, 54.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.9ms\n",
            "Speed: 0.6ms preprocess, 54.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 60.8ms\n",
            "Speed: 0.6ms preprocess, 60.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 56.9ms\n",
            "Speed: 0.6ms preprocess, 56.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.9ms\n",
            "Speed: 0.6ms preprocess, 51.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 53.5ms\n",
            "Speed: 0.6ms preprocess, 53.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.2ms\n",
            "Speed: 0.9ms preprocess, 52.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.6ms\n",
            "Speed: 0.6ms preprocess, 52.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.2ms\n",
            "Speed: 0.6ms preprocess, 52.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.7ms\n",
            "Speed: 0.7ms preprocess, 51.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.7ms\n",
            "Speed: 0.9ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.5ms\n",
            "Speed: 0.7ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 0.7ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 1.7ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 0.6ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.2ms\n",
            "Speed: 0.6ms preprocess, 42.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.5ms\n",
            "Speed: 2.5ms preprocess, 39.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.7ms\n",
            "Speed: 0.6ms preprocess, 39.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.7ms\n",
            "Speed: 1.1ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.5ms\n",
            "Speed: 0.6ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.4ms\n",
            "Speed: 0.7ms preprocess, 44.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.6ms\n",
            "Speed: 0.6ms preprocess, 39.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 43.4ms\n",
            "Speed: 0.6ms preprocess, 43.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 43.8ms\n",
            "Speed: 0.6ms preprocess, 43.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.4ms\n",
            "Speed: 0.5ms preprocess, 45.4ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.6ms\n",
            "Speed: 0.6ms preprocess, 45.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.1ms\n",
            "Speed: 0.9ms preprocess, 45.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.5ms\n",
            "Speed: 0.6ms preprocess, 46.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 59.2ms\n",
            "Speed: 0.7ms preprocess, 59.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 56.6ms\n",
            "Speed: 0.6ms preprocess, 56.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 refrigerator, 64.4ms\n",
            "Speed: 0.5ms preprocess, 64.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 65.9ms\n",
            "Speed: 0.6ms preprocess, 65.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 62.3ms\n",
            "Speed: 0.6ms preprocess, 62.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 62.7ms\n",
            "Speed: 0.6ms preprocess, 62.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 70.9ms\n",
            "Speed: 0.6ms preprocess, 70.9ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.2ms\n",
            "Speed: 2.7ms preprocess, 64.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 64.5ms\n",
            "Speed: 0.9ms preprocess, 64.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 60.5ms\n",
            "Speed: 0.6ms preprocess, 60.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 51.8ms\n",
            "Speed: 0.6ms preprocess, 51.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 51.2ms\n",
            "Speed: 0.6ms preprocess, 51.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 51.5ms\n",
            "Speed: 0.6ms preprocess, 51.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 51.3ms\n",
            "Speed: 0.6ms preprocess, 51.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 51.4ms\n",
            "Speed: 0.6ms preprocess, 51.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 45.2ms\n",
            "Speed: 0.6ms preprocess, 45.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 44.8ms\n",
            "Speed: 0.7ms preprocess, 44.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 44.8ms\n",
            "Speed: 0.8ms preprocess, 44.8ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 41.7ms\n",
            "Speed: 0.6ms preprocess, 41.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 40.9ms\n",
            "Speed: 0.5ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 41.0ms\n",
            "Speed: 0.6ms preprocess, 41.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 40.9ms\n",
            "Speed: 0.6ms preprocess, 40.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    }
  ]
}